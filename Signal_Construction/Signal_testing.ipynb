{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This file will serve as the main testing ground for a variety of signals for the CRSP data set\n",
    "\n",
    "## The multiple strategies are the underlying:\n",
    "\n",
    "### 1. Univariate Strategies\n",
    "   * MACD (momentum), bollinger bands (mean reversion), univariate KRR\n",
    "   \n",
    "### 2. Multivariate Strategies\n",
    "   * multivariate KRR, VAR\n",
    "   \n",
    "### 3. NN-based methodologies\n",
    "   \n",
    "### 4. Others? (eg. from academic literature)\n",
    "\n",
    "### Further to do:\n",
    "   * include fractional differentiation to maximise memory & keep stationarity\n",
    "   * perform necessary statistical tests on VAR & its parameters\n",
    "        * get VAR to work only with cointegrated pairs\n",
    "   * generally: optimize code & parallelize operations\n",
    "   * **ideas to include:**\n",
    "       * PLS (pure dimension reduction but keeping objective), elastic net (as a way to include penalization methods)\n",
    "       * momentum: L5 ledoit & wolf notes: straight momentum, echo momentum, momentum consistency, momentum acceleration\n",
    "       * pairs trading strategy using cointegration\n",
    "       * mean reversion: individual and in pairs\n",
    "       * relative strength index (RSI)\n",
    "   * delve deeper into cross validation methodologies for each method, making sure all parameters are fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:28:03.593540Z",
     "start_time": "2022-02-01T16:28:03.574541Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import statsmodels as sm\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import *\n",
    "from sklearn.kernel_ridge import *\n",
    "from sklearn import linear_model\n",
    "import math\n",
    "import scipy\n",
    "from statsmodels.tsa.api import VAR\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tools.eval_measures import rmse, aic\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.tsa.vector_ar.vecm import coint_johansen\n",
    "from scipy.stats.mstats import winsorize\n",
    "from scipy.stats import chi2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:22:41.419546Z",
     "start_time": "2022-02-01T16:22:40.783257Z"
    }
   },
   "outputs": [],
   "source": [
    "data  = pd.read_csv('data/returns.csv')\n",
    "data.set_index('date', inplace=True)\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data = data.iloc[:,:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate strategies\n",
    "* Simple strategies\n",
    "    + mean reversion -> DONE\n",
    "    + momentum (MACD) -> DONE\n",
    "* forecasting strategies (requires cross-validation procedure)\n",
    "    + ARMA\n",
    "    + KRR (extremely slow) -> DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:28:06.935335Z",
     "start_time": "2022-02-01T16:28:06.832778Z"
    }
   },
   "outputs": [],
   "source": [
    "def macd(ret, long=26, short=12, signal_span=9, plot=False):\n",
    "\n",
    "    short_signal = ret.ewm(span=short, adjust=False).mean()\n",
    "    long_signal = ret.ewm(span=long, adjust=False).mean() \n",
    "    macd = short_signal - long_signal\n",
    "    \n",
    "    pos = np.zeros(len(ret))\n",
    "    pos = np.where(macd>0,1,-1)\n",
    "    \n",
    "    if plot==True:\n",
    "        %matplotlib widget\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(ret.index[:100],signal[:100], label = 'signal', color='g')\n",
    "        ax.plot(ret.index[:100],macd[:100], label = 'macd', color = 'b')\n",
    "        ax.legend(loc=1)\n",
    "        ax.set_xlabel(\"time\")\n",
    "        ax.set_ylabel(\"MACD/SIGNAL\")\n",
    "        \n",
    "        months = mdates.MonthLocator()\n",
    "        ax.xaxis.set_major_locator(months) \n",
    "        fig.autofmt_xdate()\n",
    "        \n",
    "        ax2 = ax.twinx()\n",
    "        ax2.stem(stock.index[:100],position[:100])\n",
    "        ax2.set_ylabel(\"position (1 for long, 0 for none, -1 for short)\")\n",
    "        ax2.set_ylim(-3,3)\n",
    "        ax.set_title(\"MACD strategy visualised with positions as stems for first 100 observations\")\n",
    "        plt.show()\n",
    "    \n",
    "    return pos\n",
    "\n",
    "def macd_signals(returns,long=26,short=12,signal_span=9):\n",
    "    signals = pd.DataFrame()\n",
    "    for i in range(returns.shape[1]):\n",
    "        signals['signal_{}'.format(i)] = macd(returns.iloc[:,i],long,short,signal_span)\n",
    "    signals.index = returns.index\n",
    "    return signals.shift(1).fillna(0)\n",
    "\n",
    "# figure out way to use this function -> more efficient code\n",
    "def rolling_pipe(dataframe, window, fctn):\n",
    "    return pd.Series([dataframe.iloc[i-window: i].pipe(fctn) \n",
    "                      if i >= window else None \n",
    "                      for i in range(1, len(dataframe)+1)],\n",
    "                     index = dataframe.index) \n",
    "\n",
    "# bollinger bands: mean reversion\n",
    "def rev(ret,lookback,band,plot):\n",
    "    # work with prices\n",
    "    p = (ret+1).cumprod()\n",
    "    # obtain mean & vol\n",
    "    m = p.rolling(window=lookback).mean()\n",
    "    s = p.rolling(window=lookback).std()\n",
    "    lower_band = m - band*s\n",
    "    higher_band = m + band*s\n",
    "    \n",
    "    #signal = np.where(ret > higher_band,-1,\n",
    "    #                  np.where(ret < m, 0,\n",
    "    #                           np.where(ret < lower_band, 1,0)))\n",
    "    \n",
    "    signal2 = np.zeros(len(ret))\n",
    "    position_short = False\n",
    "    position_long = False\n",
    "    for i in range(len(ret)):\n",
    "        # sell if higher than band\n",
    "        if p[i] > higher_band[i]:\n",
    "            signal2[i] = -1\n",
    "            position_short = True\n",
    "        # sell back if from lower band to mean\n",
    "        elif p[i] < higher_band[i] and p.iloc[i] > m[i] and position_long == True:\n",
    "            signal2[i] = 0\n",
    "            position_long = False\n",
    "        # buy back if from higher band to mean\n",
    "        elif p[i] < m[i] and position_short == True:\n",
    "            signal2[i] = 0\n",
    "            position_short = False\n",
    "        # buy if lower barrier hit\n",
    "        elif p[i] < lower_band[i]:\n",
    "            signal2[i] = 1\n",
    "            position_long = True\n",
    "        else:\n",
    "            signal2[i] = signal2[i-1]\n",
    "        \n",
    "\n",
    "    if plot==True:\n",
    "        %matplotlib widget\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.plot(ret.index,lower_band, label = 'lower', color='b')\n",
    "        ax.plot(ret.index,higher_band, label = 'higher', color = 'b')\n",
    "        ax.plot(ret.index,m, label = 'mean', color = 'b')\n",
    "        ax.plot(ret.index,p,label=\"returns\", color=\"r\")\n",
    "\n",
    "        ax.legend(loc=1)\n",
    "        ax.set_xlabel(\"TIME\")\n",
    "        ax.set_ylabel(\"PRICE\")\n",
    "\n",
    "        months = mdates.MonthLocator()\n",
    "        ax.xaxis.set_major_locator(months) \n",
    "        fig.autofmt_xdate()\n",
    "\n",
    "        plt.show()\n",
    "        \n",
    "    return signal2\n",
    "\n",
    "\n",
    "def reversion_signals(returns,lookback=100,band=2,plot=False):\n",
    "    signals = pd.DataFrame()\n",
    "    for i in range(returns.shape[1]):\n",
    "        signals['signal_{}'.format(i)] = rev(ret = returns.iloc[:,i],lookback=lookback,band=band,plot=plot)\n",
    "    signals.index = returns.index\n",
    "    return signals.shift(1).fillna(0)\n",
    "\n",
    "# kernel ridge\n",
    "def krr_signals(data,window_size=30,npredictions=5):\n",
    "    n = len(data)-1\n",
    "    predicted_values = np.zeros(n+npredictions+1)\n",
    "\n",
    "    \n",
    "    # rolling window\n",
    "    for i in range(window_size,n,npredictions):\n",
    "        if i % 100 == 0: print('{} % done'.format(round(i/(n-30)*100)),end=\"\\r\")\n",
    "        #    print(i)\n",
    "                \n",
    "        list_x = np.array(data.iloc[(i-window_size):i]).reshape(-1,1)\n",
    "        list_y = np.array(data.iloc[(i-window_size+1):(i+1)]) \n",
    "        list_x_pred = np.array(data.iloc[i:(i+npredictions)]).reshape(-1,1)\n",
    "        \n",
    "        parameters = {'kernel':['rbf'], 'alpha':np.arange(0.001,3,1).tolist(),'degree':np.arange(0.001,3,1).tolist()}\n",
    "        clf = GridSearchCV(KernelRidge(), parameters)\n",
    "        clf = clf.fit(list_x,list_y)\n",
    "        pred = clf.predict(list_x_pred)\n",
    "        predicted_values[i:(i+npredictions)] = pred\n",
    "    \n",
    "    # turn values into signals\n",
    "    signals = np.where(predicted_values > 0,1,-1)\n",
    "    \n",
    "    return signals\n",
    "def krr_signals_univ(data,window_size=30,npredictions=5):\n",
    "    n = data.shape[0]\n",
    "    signals = np.zeros((n+npredictions,data.shape[1]))\n",
    "    for i in range(data.shape[1]):\n",
    "        signals[:,i] = krr_signals(data.iloc[:,i],window_size=window_size,npredictions=npredictions)\n",
    "    return signals\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Econometric\n",
    "   * Vector Autoregressive (VAR) -> DONE\n",
    "   * Vector error correction models (VECM)\n",
    "   * Kernel Ridge Regression (KRR) -> DONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistical tests\n",
    "   * **Granger causality** (column var causes row var) -> rejection means good candidate for MV\n",
    "       (tests the null hypothesis that the coefficients of past values in the regression equation is zero. In simpler terms, the past values of time series (X) do not cause the other series (Y))\n",
    "   * **ADF test** -> need stationarity in time series\n",
    "   * **cointegration** -> establish the presence of a statistically significant connection between two or more time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:28:07.656864Z",
     "start_time": "2022-02-01T16:28:07.635576Z"
    }
   },
   "outputs": [],
   "source": [
    "def grangers_causation_matrix(data, variables, test='ssr_chi2test', maxlag=4):    \n",
    "    \"\"\"\n",
    "    data      : pandas dataframe containing the time series variables\n",
    "    variables : list containing names of the time series variables.\n",
    "    \"\"\"\n",
    "    df = pd.DataFrame(np.zeros((len(variables), len(variables))), columns=variables, index=variables)\n",
    "    for c in df.columns:\n",
    "        for r in df.index:\n",
    "            test_result = grangercausalitytests(data[[r, c]], maxlag=maxlag, verbose=False)\n",
    "            p_values = [round(test_result[i+1][0][test][1],4) for i in range(maxlag)]\n",
    "            min_p_value = np.min(p_values)\n",
    "            df.loc[r, c] = min_p_value\n",
    "    df.columns = [var + '_x' for var in variables]\n",
    "    df.index = [var + '_y' for var in variables]\n",
    "    return df\n",
    "\n",
    "def adfuller_test(series, signif=0.05):\n",
    "    \"\"\"Perform ADFuller to test for Stationarity of given series of returns and print report\"\"\"\n",
    "    for name, column in series.iteritems():\n",
    "        r = adfuller(column, autolag='BIC')\n",
    "        output = {'test_statistic':round(r[0], 4), 'pvalue':round(r[1], 4), 'n_lags':round(r[2], 4), 'n_obs':r[3]}\n",
    "        p_value = output['pvalue']\n",
    "        if p_value > signif:\n",
    "            print(\"series {} is non-stationary\".format(column.name))\n",
    "            \n",
    "def cointegration_test(df, alpha=0.05): \n",
    "    \"\"\"Perform Johanson's Cointegration Test and Report Summary\"\"\"\n",
    "    out = coint_johansen(df,-1,5)\n",
    "    d = {'0.90':0, '0.95':1, '0.99':2}\n",
    "    traces = out.lr1\n",
    "    cvts = out.cvt[:, d[str(1-alpha)]]\n",
    "    # print output if failed\n",
    "    for name, trace, cvt in zip(df.columns, traces, cvts):\n",
    "        if trace < cvt: print(\"column {} failed the cointegration test\".format(name))\n",
    "\n",
    "def multivariate_tests(data,alpha=0.05,maxlag=4, test = 'ssr_chi2test'):\n",
    "    \"\"\"\n",
    "    data: pandas dataframe\n",
    "    alpha: significance level\n",
    "    maxlag: maximum number of lags for granger causality test\n",
    "    test: test for granger causality\n",
    "    \n",
    "    what it does: prints failed adf and cointegration tests\n",
    "    \n",
    "    returns: granger causality matrix\n",
    "    \"\"\"\n",
    "    adfuller_test(data, signif=alpha)\n",
    "    cointegration_test(data, alpha=alpha)\n",
    "    \n",
    "    return grangers_causation_matrix(data, data.columns, test=test, maxlag=maxlag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAR model\n",
    "still requires some code optimisation\n",
    "\n",
    "suggested improvements: build model using solely cointegrated time series -> can include more lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:28:08.335165Z",
     "start_time": "2022-02-01T16:28:08.301004Z"
    }
   },
   "outputs": [],
   "source": [
    "def var(df, window=30,maxlag=3,npredictions=5):\n",
    "    \n",
    "    n = len(df)\n",
    "    # initiate forecasts dataframe\n",
    "    forecasts = np.zeros((n+npredictions,df.shape[1])) \n",
    "    \n",
    "    # rolling window approach\n",
    "    for i in range(window,n,npredictions):\n",
    "        if i % 250 == 0: print('{}% done'.format(round(i/(n-30)*100)),end=\"\\r\")\n",
    "        bic_list = []\n",
    "        series = df.iloc[(i-window):i,:]\n",
    "        model = VAR(series)\n",
    "        \n",
    "        # optimal lags and fitting\n",
    "        for j in np.arange(0,maxlag+1,1):\n",
    "            try:\n",
    "                result = model.fit(j)\n",
    "                bic_list.append(result.bic)\n",
    "            except:\n",
    "                print(\"cannot deal with lag of {}, restarting with maxlag of {}\".format(j,maxlag-1))\n",
    "                if maxlag == 0:\n",
    "                    print(\"window size too small relative to number of assets, please restart\")\n",
    "                    return 0\n",
    "                else:\n",
    "                    return var(df, window, maxlag-1)\n",
    "        \n",
    "        # final check\n",
    "        if len(bic_list) == 1:\n",
    "                print(\"window size too small relative to number of assets, please restart\")\n",
    "                return 0   \n",
    "            \n",
    "        nbr_lags = bic_list.index(min(bic_list)) + 1\n",
    "        model_fitted = model.fit(nbr_lags)\n",
    "\n",
    "        forecast_input = series.values[-nbr_lags:]\n",
    "        \n",
    "        fc = model_fitted.forecast(y=forecast_input, steps=npredictions)\n",
    "        forecasts[i:(i+npredictions),:] = fc\n",
    "        \n",
    "    signals = np.where(forecasts > 0,1,-1)\n",
    "\n",
    "                \n",
    "    return signals\n",
    "\n",
    "def krr_signals_mv(data,window_size=30,npredictions=5):\n",
    "    n = len(data)-1\n",
    "\n",
    "    predicted_values = np.zeros((n+npredictions+1,data.shape[1]))    \n",
    "\n",
    "    # rolling window\n",
    "    # re-fit the model every \"npredictions\" days\n",
    "    for i in range(window_size,n,npredictions):\n",
    "        if i % 100 == 0: print('{} % done'.format(round(i/(n-window_size)*100)),end=\"\\r\")\n",
    "        begin = i - window_size\n",
    "        \n",
    "        # obtain principal components, section 2.5\n",
    "        pca = PCA(n_components=4)\n",
    "        principalComponents = pca.fit_transform(np.array(data.iloc[begin:i,:]))\n",
    "        \n",
    "        principalDf = pd.DataFrame(data = principalComponents, columns = ['pc1','pc2','pc3','pc4'])\n",
    "        \n",
    "        model = linear_model.LinearRegression()\n",
    "        model_score = model.fit(principalDf,data.iloc[begin:i,:]).score(principalDf,data.iloc[begin:i,:])\n",
    "        \n",
    "        x = np.array(data.iloc[(i-window_size):i,:])#.reshape(-1,1)\n",
    "        y = np.array(data.iloc[(i-window_size+1):(i+1),:]) \n",
    "        x_pred = np.array(data.iloc[i:(i+npredictions),:])\n",
    "        \n",
    "        # gaussian kernel parameters\n",
    "        nbr_assets = data.shape[1]\n",
    "        df = window_size - nbr_assets\n",
    "        if df<0:df=1 # for chi-square\n",
    "        r2 = np.array(model_score)\n",
    "        sigma0 = math.sqrt(chi2.ppf(0.95,df)) / math.pi\n",
    "        sigma = np.array([0.5*sigma0,sigma0,2*sigma0,4*sigma0,8*sigma0])\n",
    "        lambda0 = (1-r2)/(r2)\n",
    "        lambdaa = np.array([lambda0/8.0,lambda0/4.0,lambda0/2.0,lambda0,2*lambda0])\n",
    "        \n",
    "        parameters = {'kernel':['rbf'], 'alpha':lambdaa.tolist(),'degree':[2]}\n",
    "        clf = GridSearchCV(KernelRidge(), parameters)\n",
    "        clf = clf.fit(x,y)\n",
    "        pred = clf.predict(x_pred)\n",
    "        predicted_values[i:(i+npredictions),:] = pred\n",
    "    \n",
    "    # turn values into signals\n",
    "    signals = np.where(predicted_values > 0,1,-1)\n",
    "    \n",
    "    return signals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN-based methodologies\n",
    "   * LSTM\n",
    "   * CNN\n",
    "   * other?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (initial) Testing the strategies\n",
    "\n",
    "Conclusions:\n",
    "   * standard MACD, mean reversion and VAR are bad strategies, all beaten by long only\n",
    "   * KRR performs very well on average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-01T16:28:10.090827Z",
     "start_time": "2022-02-01T16:28:10.074791Z"
    }
   },
   "outputs": [],
   "source": [
    "# performance evaluation\n",
    "def pnl(data,signals):\n",
    "    d = np.array(data)\n",
    "    s = np.array(signals)\n",
    "    return (1 + pd.DataFrame(np.multiply(d,s), index=data.index)).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-01T16:28:10.547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "macd done\n",
      "mean reversion done\n",
      "krr univariate done\n",
      "20 % done\r"
     ]
    }
   ],
   "source": [
    "stocks = data\n",
    "# 1. test macd\n",
    "macd_multiple = macd_signals(stocks,26,12,9)\n",
    "print(\"macd done\")\n",
    "# 2. test mean reversion\n",
    "#m_r = reversion_signals(stocks)\n",
    "print(\"mean reversion done\")\n",
    "# 3. test krr univariate\n",
    "#krr_univ = krr_signals_univ(stocks)\n",
    "print(\"krr univariate done\")\n",
    "# 4. test krr multivariate\n",
    "krr_mv = krr_signals_mv(stocks)\n",
    "print(\"krr multivariate done\")\n",
    "# 5. test VAR -> cannot deal with very high dimensions\n",
    "var_s = var(stocks.iloc[:,:5],window = 30,maxlag=3,npredictions=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-01T16:28:24.143Z"
    }
   },
   "outputs": [],
   "source": [
    "macd_perf = pnl(stocks,macd_multiple)\n",
    "m_r_perf = pnl(stocks,m_r)\n",
    "krr_perf = pnl(stocks,krr_mv[:-5,:])\n",
    "#krr2_perf = pnl(stocks,krr_univ[:-5,:])\n",
    "var_perf = pnl(stocks.iloc[:,:5],var_s[:-5,:])\n",
    "\n",
    "# skip first 30 days -> window size\n",
    "macd_perf = macd_perf.iloc[30:,:]\n",
    "m_r_perf = m_r_perf.iloc[30:,:]\n",
    "krr_perf = krr_perf.iloc[30:,:]\n",
    "#krr2_perf = krr2_perf.iloc[30:,:]\n",
    "var_perf = var_perf.iloc[30:,:]\n",
    "long_only = (1+stocks.iloc[30:,:]).cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-02-01T16:28:25.496Z"
    }
   },
   "outputs": [],
   "source": [
    "index = macd_perf.index\n",
    "%matplotlib widget\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(index,macd_perf.mean(axis=1), label = 'macd', color = 'r')\n",
    "ax.plot(index,krr_perf.mean(axis=1), label = 'krr multivariate', color = 'b')\n",
    "#ax.plot(index,krr2_perf.mean(axis=1), label = 'krr univariate', color = 'b')\n",
    "ax.plot(index,m_r_perf.mean(axis=1), label = 'mean reversion', color = 'g')\n",
    "ax.plot(index,long_only.mean(axis=1), label = 'real', color = 'y')\n",
    "ax.plot(index,var_perf.mean(axis=1), label = 'var', color = 'gray')\n",
    "\n",
    "ax.legend(loc=0)\n",
    "ax.grid()\n",
    "ax.set_xlabel(\"Time\")\n",
    "ax.set_ylabel(\"Multiple\")\n",
    "#ax2.set_ylabel(\"pred\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
