{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction Cost analysis and Statistical Tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T17:40:30.677087Z",
     "start_time": "2022-08-23T17:40:28.110084Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import os\n",
    "import pickle\n",
    "import cvxpy as cp\n",
    "from scipy.optimize import minimize\n",
    "from project_lib.backtest import *\n",
    "from project_lib.utils import *\n",
    "from project_lib.performance import *\n",
    "from project_lib.analysis import *\n",
    "from project_lib.portfolio import Portfolio\n",
    "from project_lib.backtest import *\n",
    "\n",
    "HOME_DIRECTORY = 'C:/Users/Harol/OneDrive/Documents/master computational finance/thesis/thesis_UCL/Code/Transaction Costs'\n",
    "sys.path.append(HOME_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:20.481520Z",
     "start_time": "2022-08-23T19:40:20.448523Z"
    }
   },
   "outputs": [],
   "source": [
    "# import returns\n",
    "with open(HOME_DIRECTORY + '/data/processed_daily_data/ret_subset.pkl', 'rb') as f:\n",
    "    ret = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:20.607521Z",
     "start_time": "2022-08-23T19:40:20.592527Z"
    }
   },
   "outputs": [],
   "source": [
    "universe_size = 50\n",
    "ret = ret.iloc[:, :universe_size]  # subset the data\n",
    "ret = ret.iloc[(4):] # burn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:21.144198Z",
     "start_time": "2022-08-23T19:40:21.120198Z"
    }
   },
   "outputs": [],
   "source": [
    "prices = (1 + ret).cumprod()\n",
    "prices = prices.iloc[:,:universe_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:51.840435Z",
     "start_time": "2022-08-23T19:38:51.312990Z"
    }
   },
   "outputs": [],
   "source": [
    "lcca_ls = pd.read_excel(\"weights_l4_pfrevers_ls.xlsx\",sheet_name=\"30assets_sig_pfrevers_ls\")\n",
    "lcca_nls = pd.read_excel(\"weights_l4_pfrevers_nls.xlsx\",sheet_name=\"30assets_sig_pfrevers_nls\")\n",
    "lcca_weights = [lcca_ls, lcca_nls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:54.490108Z",
     "start_time": "2022-08-23T19:38:51.843023Z"
    }
   },
   "outputs": [],
   "source": [
    "l6mean_rev = pd.read_excel(\"weights_l6_2.xlsx\",sheet_name=\"50assets_sig_mean_rev_sample\")\n",
    "l6prs = pd.read_excel(\"weights_l6_3.xlsx\",sheet_name=\"50assets_sig_prs_sample\")\n",
    "l6mtm = pd.read_excel(\"weights_l6_4.xlsx\",sheet_name=\"50assets_sig_mtm_sample\")\n",
    "l6pfrevers = pd.read_excel(\"weights_l6_5.xlsx\",sheet_name=\"50assets_sig_pfrevers_sample\")\n",
    "l6rev = pd.read_excel(\"weights_l6_6.xlsx\",sheet_name=\"50assets_sig_rev_sample\")\n",
    "ncca_weights = [l6mean_rev,l6prs,l6mtm,l6pfrevers,l6rev]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:54.504993Z",
     "start_time": "2022-08-23T19:38:54.491993Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(df,col,indent,datename,norm):\n",
    "    df = df.set_index(df.columns[col])\n",
    "    df.index.names = [datename]\n",
    "    df.index = pd.to_datetime(df.index)\n",
    "    df = df.iloc[indent:,:]\n",
    "    if norm:\n",
    "        m = df.div(df.std(axis=1), axis=0)\n",
    "        df = m\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:54.551609Z",
     "start_time": "2022-08-23T19:38:54.509001Z"
    }
   },
   "outputs": [],
   "source": [
    "for d in range(len(lcca_weights)):\n",
    "    lcca_weights[d] = preprocess(lcca_weights[d],0,0,\"date\",True)\n",
    "for d in range(len(ncca_weights)):\n",
    "    ncca_weights[d] = preprocess(ncca_weights[d],0,0,\"date\",True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transaction cost on asset level\n",
    "\n",
    "Implementation of \"Multiperiod portfolio optimization with multiple risky assets and general transaction costs\", Mei, Demiguel, Nogales, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:54.567457Z",
     "start_time": "2022-08-23T19:38:54.554463Z"
    }
   },
   "outputs": [],
   "source": [
    "def rebalancing(X,X_prev, rho, gamma, kappa, mu,sigma, lag, target=\"Markowitz\"):\n",
    "    \"\"\"\n",
    "        Function to calculate optimal rebalancing on asset level with proportional transaction costs.\n",
    "        \n",
    "        Implementation equation (2) in Multiperiod portfolio optimization with multiple risky assets\n",
    "        and general transaction costs.\n",
    "        \n",
    "        Inputs:\n",
    "                X      : target weights                   [1 x m]\n",
    "                X_prev : previous weights                 [1 x m]\n",
    "                rho    : discount rate                    [1 x 1]\n",
    "                gamma  : absolute risk-aversion parameter [1 x 1]\n",
    "                kappa  : transaction cost parameter       [1 x 1]\n",
    "                mu     : mean returns                     [1 x m]\n",
    "                sigma  : covariance of returns            [m x m]\n",
    "                lag    : rebalancing horizon              [1 x 1]\n",
    "        Output:\n",
    "                new_w : new weights [1 x m]\n",
    "    \"\"\"\n",
    "    \n",
    "    if target==\"Markowitz\":\n",
    "        constraints = []\n",
    "        m = len(X)\n",
    "        # initiliase variable\n",
    "        w = cp.Variable(m)\n",
    "        # objective function\n",
    "        obj = cp.Maximize((1-rho)**lag * (w * mu - gamma/2 * w * sigma * w) - kappa*cp.norm(w - X_prev, 1))\n",
    "        prob = cp.Problem(obj, constraints)\n",
    "        prob.solve(verbose = False)\n",
    "        new_w = np.array(w.value)\n",
    "        \n",
    "    elif target==\"Target\":\n",
    "        # Calculated using SCIPY (CVXPY does not support formulation)\n",
    "        arguments = (X, kappa, X_prev)\n",
    "        res = minimize(minimize_target, x0=X, args=arguments)\n",
    "        new_w = res.x\n",
    "        \n",
    "    elif target == \"Tradeoff\":\n",
    "        # Calculated using SCIPY (CVXPY does not support formulation)\n",
    "        arguments = (X, X_prev, gamma, kappa, sigma)\n",
    "        res = minimize(minimize_tradeoff, x0 = X, args = arguments)\n",
    "        new_w = res.x\n",
    "\n",
    "    return new_w\n",
    "\n",
    "def minimize_target(w, w_target, tcost, w_prev):\n",
    "    \"\"\"\n",
    "        minimizes difference between target weights and actual weights whilst penalizing for difference with previous weights\n",
    "        \n",
    "        Equation : w_target - w + tcost * |w - w_prev|\n",
    "        \n",
    "        inputs:\n",
    "                w        : actual weights                   [1 x m]\n",
    "                w_target : target weights                   [1 x m]\n",
    "                w_prev   : previous weights                 [1 x m]\n",
    "                tcost  : transaction cost parameter         [1 x 1]\n",
    "        outputs:\n",
    "                norm1 of Equation\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(w_target-w + tcost * np.abs(w - w_prev),1)\n",
    "\n",
    "def minimize_tradeoff(w,w_target,w_prev,gamma,tcost,covar):\n",
    "    \"\"\"\n",
    "        minimizes difference between target weights and actual weights whilst penalizing for\n",
    "        the difference with previous weights. Taking into account the covariance matrix, risk aversion (tracking error)\n",
    "        and transaction cost parameter.\n",
    "        \n",
    "        Equation 1 in \"Analytical solutions of optimal portfolio rebalancing\", Ding Liu, 2019\n",
    "        \n",
    "        inputs:\n",
    "                w        : actual weights                   [1 x m]\n",
    "                w_target : target weights                   [1 x m]\n",
    "                w_prev   : previous weights                 [1 x m]\n",
    "                gamma  : absolute risk-aversion parameter   [1 x 1]\n",
    "                tcost  : transaction cost parameter         [1 x 1]\n",
    "                covar  : covariance of returns              [m x m]\n",
    "        outputs:\n",
    "                norm1 of Equation 1\n",
    "        \n",
    "    \"\"\"\n",
    "    # norm1[ 1/(2*gamma) * (w - w_T) @ covar @ (w-w_T)' + tcost * (w - w_(t-1))' ]\n",
    "    return np.linalg.norm( (1 / (2*gamma)) * (w - w_target) @ covar @ (w - w_target).T + tcost * np.abs(w - w_prev), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:55.193366Z",
     "start_time": "2022-08-23T19:38:55.184368Z"
    }
   },
   "outputs": [],
   "source": [
    "def constant_rebalancing(weights, rho, gamma, kappa, returns, lag, target):\n",
    "    \"\"\"\n",
    "        function to perform continuous rebalancing taking into account transaction costs\n",
    "\n",
    "    \"\"\"\n",
    "    # create some variables\n",
    "    means = returns.rolling(250).mean().iloc[250:, :]\n",
    "    #covariances = returns.rolling(250).cov()\n",
    "    covariances = 1\n",
    "    new_weights = weights.copy()\n",
    "\n",
    "    new_weights.iloc[0, :] = new_weights.iloc[0, :]\n",
    "\n",
    "    # first very basic function\n",
    "    for i in range(1, weights.shape[0]):\n",
    "        if i % 50 == 0:\n",
    "            print(\"iteration {}\".format(i))\n",
    "        target_w = np.array(weights.iloc[i, :])\n",
    "        prev_w = np.array(new_weights.iloc[i-1, :])\n",
    "\n",
    "        covariances = get_cov(\n",
    "            np.array(returns.iloc[i:(i+250), :]), method=\"nls\", square_root=False)\n",
    "\n",
    "        temp = rebalancing(target_w, prev_w, rho=rho,\n",
    "                           gamma=gamma, kappa=kappa, mu=means.iloc[i, :], sigma=covariances, lag=lag, target=target)\n",
    "\n",
    "        for j in range(len(temp)):\n",
    "            new_weights.iloc[i, j] = temp[j]\n",
    "\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:56.381359Z",
     "start_time": "2022-08-23T19:38:56.368361Z"
    }
   },
   "outputs": [],
   "source": [
    "def rebalancing_output_tcosts(naming,tcosts, cca_w, rho, gammas, returns, lag=1, target=\"Tradeoff\"):\n",
    "    for tcost in tcosts:\n",
    "        for gamma in gammas:\n",
    "            print(\"on tcost {} and gamma {}\".format(tcost,gamma))\n",
    "            tcost_weights = constant_rebalancing(cca_w, rho=rho, gamma=gamma,\n",
    "                                                 kappa=tcost, returns=returns, lag=lag, target=target)\n",
    "            tcost_weights.to_csv(naming+str(tcost)+\"_\"+str(gamma)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## impact of different levels of transaction costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:57.915550Z",
     "start_time": "2022-08-23T19:38:57.896517Z"
    }
   },
   "outputs": [],
   "source": [
    "tcosts = [0.0001,0.0002,0.0003]\n",
    "gammas = [0.25, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T11:50:00.519146Z",
     "start_time": "2022-08-23T11:32:31.893522Z"
    }
   },
   "outputs": [],
   "source": [
    "# name\n",
    "name_convention = \"ncca_rev_\"\n",
    "rebalancing_output_tcosts(name_convention, tcosts,\n",
    "                          cca_w=ncca_weights[1], rho=0, gammas=gammas, returns=ret, lag=1, target=\"Tradeoff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import previously extracted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:40.267592Z",
     "start_time": "2022-08-23T19:40:40.249598Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_tcost_files(variable_list, base_name,sample_name,include_sample = True):\n",
    "    \n",
    "    # extract data frames and put them into a list\n",
    "    list_of_files = [pd.read_csv(base_name+i+\".csv\") for i in variable_list]\n",
    "    \n",
    "    if include_sample:\n",
    "        assert len(sample_name) != 0, \"if you want to include sample cca name, include its file names\" \n",
    "        list_of_files.insert(0,pd.read_csv(sample_name))\n",
    "        \n",
    "    # some quick preprocessing\n",
    "    for df in list_of_files:\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.set_index(\"Unnamed: 0\", inplace=True)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.index.names = ['date']\n",
    "        elif \"date\" in df.columns:\n",
    "            df.set_index(\"date\", inplace=True)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.index.names = ['date']\n",
    "        \n",
    "    return list_of_files\n",
    "\n",
    "def list_to_dict(keys, lst):\n",
    "    return dict(zip(transaction_costs,cca_tcosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:40.567056Z",
     "start_time": "2022-08-23T19:40:40.553011Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "combinations = [str(i)+\"_\"+str(j) for i in tcosts for j in gammas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:41.445412Z",
     "start_time": "2022-08-23T19:40:41.344951Z"
    }
   },
   "outputs": [],
   "source": [
    "# assign dataset names\n",
    "name_convention = \"ncca_mtm_\"\n",
    "results = extract_tcost_files(variable_list=combinations,\n",
    "                                 base_name=name_convention,\n",
    "                                 sample_name=\"sample_cca_weights.csv\",\n",
    "                                 include_sample=False)\n",
    "\n",
    "# create dictionary from list\n",
    "transaction_costs = [str(i) for i in combinations]\n",
    "transaction_costs.insert(0,\"sample\")\n",
    "cca_dict = dict(zip(combinations, results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### evaluate performance\n",
    "\n",
    "dictionary to use is *cca_dict*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:44.928463Z",
     "start_time": "2022-08-23T19:40:44.856463Z"
    }
   },
   "outputs": [],
   "source": [
    "pnl_results = dict()\n",
    "ptf_ret = dict()\n",
    "for k,tc in enumerate(cca_dict):\n",
    "    print(tc[:6])\n",
    "    # we turn 'tc' into a float, which is why there is a separation\n",
    "    if tc!=\"sample\":     \n",
    "        portfolio =  Portfolio(prices=prices.loc[cca_dict[tc].index], position=cca_dict[tc], period=0,tcost=np.float(tc[:6]))\n",
    "        ptf_ret[tc] = portfolio.adjusted_profit.to_frame(name=\"Profit\")\n",
    "        pnl_results[tc] = portfolio.adjusted_nav().to_frame(name=\"NAV\")\n",
    "    else:\n",
    "        portfolio =  Portfolio(prices=prices.loc[cca_dict[tc].index], position=cca_dict[tc], period=0,tcost=0)\n",
    "        ptf_ret[tc] = portfolio.adjusted_profit.to_frame(name=\"Profit\")\n",
    "        pnl_results[tc] = portfolio.adjusted_nav().to_frame(name=\"NAV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:40:48.957017Z",
     "start_time": "2022-08-23T19:40:48.881974Z"
    }
   },
   "outputs": [],
   "source": [
    "nls_summ = build_table2(combinations, ptf_ret)\n",
    "nls_summ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:41:17.314557Z",
     "start_time": "2022-08-23T19:41:17.233520Z"
    }
   },
   "outputs": [],
   "source": [
    "build_table3(combinations, cca_dict, ptf_ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:41:17.827358Z",
     "start_time": "2022-08-23T19:41:17.625986Z"
    }
   },
   "outputs": [],
   "source": [
    "plotting(pnl_results, combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistical corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:25:59.420495Z",
     "start_time": "2022-08-23T19:25:59.416496Z"
    }
   },
   "outputs": [],
   "source": [
    "from arch.bootstrap import SPA, MCS\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:26:09.190237Z",
     "start_time": "2022-08-23T19:26:09.177238Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_1samp, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:35:45.187838Z",
     "start_time": "2022-08-23T19:35:45.177865Z"
    }
   },
   "outputs": [],
   "source": [
    "def adjust_sharpe(sharpes, T, method=\"bonferonni\"):\n",
    "    \"\"\"\n",
    "    computes a number of test statistics for trading strategies\n",
    "    input : sharpe ratios (np.ndarray), T, length of sample (int)\n",
    "    ouput : data frame of statistical significance tests of trading strategies\n",
    "    \"\"\"\n",
    "    t_stats = np.zeros(len(sharpes))\n",
    "    p_values = np.zeros(len(sharpes))\n",
    "    sharpes_adj = np.zeros(len(sharpes))\n",
    "    p_values_adj = np.zeros(len(sharpes))\n",
    "    t_stats_adj = np.zeros(len(sharpes))\n",
    "    summary = pd.DataFrame({\"sharpe\": sharpes,\n",
    "                            \"adj_sharpe\": sharpes_adj,\n",
    "                            \"p_val\": p_values,\n",
    "                            \"adj_p_val\": p_values_adj,\n",
    "                            \"t_stat\": t_stats,\n",
    "                            \"adj_t_stat\": t_stats_adj})\n",
    "    summary[\"t_stat\"] = sharpes*np.sqrt(T)\n",
    "    summary[\"p_val\"] = t.sf(summary[\"t_stat\"], df=T-1)\n",
    "\n",
    "    if method == \"holm\":  # issue with indexes\n",
    "        summary.sort_values(by=['p_val'], inplace=True)\n",
    "        summary.reset_index(inplace=True, drop=True)\n",
    "        adj_p = summary[\"p_val\"] * np.arange(1, len(summary)+1)\n",
    "        summary[\"adj_p_val\"] = [min(adj_p[i], 1) for i in range(len(summary))]\n",
    "        summary[\"adj_t_stat\"] = np.abs(t.ppf(summary[\"adj_p_val\"], df=T-1))\n",
    "        summary[\"adj_sharpe\"] = summary[\"adj_t_stat\"]/np.sqrt(T)\n",
    "        \n",
    "    elif method == \"BHY\":\n",
    "        c = np.sum([1/(i+1) for i in range(len(sharpes))])\n",
    "        # sequential loop\n",
    "        summary.sort_values(by=['p_val'], ascending=False, inplace=True)\n",
    "        summary.reset_index(inplace=True, drop=True)\n",
    "        summary.loc[0, \"adj_p_val\"] = summary.loc[0, \"p_val\"]\n",
    "    \n",
    "        for i in range(1, len(summary)):\n",
    "            summary.loc[i, \"adj_p_val\"] = min(summary.loc[i-1, \"adj_p_val\"], len(summary) * c / (i+1) *\n",
    "                                              summary.loc[i, \"p_val\"])\n",
    "            summary[\"adj_t_stat\"] = np.abs(t.ppf(summary[\"adj_p_val\"], df=T-1))\n",
    "            summary[\"adj_sharpe\"] = summary[\"adj_t_stat\"]/np.sqrt(T)\n",
    "        \n",
    "    return round(summary, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:35:45.876129Z",
     "start_time": "2022-08-23T19:35:45.848119Z"
    }
   },
   "outputs": [],
   "source": [
    "sharpes = np.array([0.8,0.81,0.11,0.14,-0.58,-0.49,0.42,0.43,-0.37,-0.32,-1.15,-1.01,0.67,0.68,0.38,\n",
    "                                0.43,-0.53,-0.44,0.05,0.06,-0.93,-0.87,-1.9,-1.8,0.45,0.46,-0.51,-0.56,-1.39,-1.26])\n",
    "adjust_sharpe(sharpes, T=750, method=\"holm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FDR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:35:46.687806Z",
     "start_time": "2022-08-23T19:35:46.632395Z"
    }
   },
   "outputs": [],
   "source": [
    "adjust_sharpe(sharpes, T=750, method=\"BHY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## white's reality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:37:59.349981Z",
     "start_time": "2022-08-23T19:37:59.336970Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_tcost_files(variable_list, base_name,sample_name,include_sample = True):\n",
    "    \n",
    "    # extract data frames and put them into a list\n",
    "    list_of_files = [pd.read_csv(base_name+i+\".csv\") for i in variable_list]\n",
    "    \n",
    "    if include_sample:\n",
    "        assert len(sample_name) != 0, \"if you want to include sample cca name, include its file names\" \n",
    "        list_of_files.insert(0,pd.read_csv(sample_name))\n",
    "        \n",
    "    # some quick preprocessing\n",
    "    for df in list_of_files:\n",
    "        if \"Unnamed: 0\" in df.columns:\n",
    "            df.set_index(\"Unnamed: 0\", inplace=True)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.index.names = ['date']\n",
    "        elif \"date\" in df.columns:\n",
    "            df.set_index(\"date\", inplace=True)\n",
    "            df.index = pd.to_datetime(df.index)\n",
    "            df.index.names = ['date']\n",
    "        \n",
    "    return list_of_files\n",
    "\n",
    "def list_to_dict(keys, lst):\n",
    "    return dict(zip(transaction_costs,cca_tcosts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:00.085194Z",
     "start_time": "2022-08-23T19:37:59.776683Z"
    }
   },
   "outputs": [],
   "source": [
    "file_names = [ \"ncca_meanrev_\", \"ncca_mtm_\",\"ncca_prs_\",\"lcca_ls_\",\"lcca_nls_\"]\n",
    "lists = []\n",
    "for f in file_names:\n",
    "    l = extract_tcost_files(variable_list=combinations,\n",
    "                                     base_name=name_convention,\n",
    "                                     sample_name=\"sample_cca_weights.csv\",\n",
    "                                     include_sample=False)\n",
    "    for new in l:\n",
    "        lists.append(new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:00.100764Z",
     "start_time": "2022-08-23T19:38:00.086749Z"
    }
   },
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "combinations = [str(i)+\"_\"+str(j) for i in tcosts for j in gammas]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:00.194934Z",
     "start_time": "2022-08-23T19:38:00.184918Z"
    }
   },
   "outputs": [],
   "source": [
    "names = [i + j + \".csv\" for i in file_names for j in combinations]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "signals to portfolio returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:00.600517Z",
     "start_time": "2022-08-23T19:38:00.583475Z"
    }
   },
   "outputs": [],
   "source": [
    "ret=ret[ret.index>=lists[0].index[0]]\n",
    "ret=ret[ret.index<=lists[0].index[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:00.834319Z",
     "start_time": "2022-08-23T19:38:00.792997Z"
    }
   },
   "outputs": [],
   "source": [
    "lists = [np.array((lists[l] * ret.iloc[:lists[l].shape[0],:lists[l].shape[1]]).sum(axis=1).values) for l in range(len(lists))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:01.009520Z",
     "start_time": "2022-08-23T19:38:01.000521Z"
    }
   },
   "outputs": [],
   "source": [
    "toarr = np.array(lists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:01.227701Z",
     "start_time": "2022-08-23T19:38:01.208702Z"
    }
   },
   "outputs": [],
   "source": [
    "combined = pd.DataFrame(columns=names,data=toarr.T,index=ret.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:01.414611Z",
     "start_time": "2022-08-23T19:38:01.408612Z"
    }
   },
   "outputs": [],
   "source": [
    "resampled= resample(np.concatenate(lists), replace=True, n_samples=combined.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "define model losses (since SPA is for predictiveness of models) as negative returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:01.867307Z",
     "start_time": "2022-08-23T19:38:01.849267Z"
    }
   },
   "outputs": [],
   "source": [
    "benchmark = np.random.normal(resampled.mean(),resampled.std(),combined.shape[0])\n",
    "bm_0 = np.random.normal(0,ret.std().mean(),combined.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:02.272669Z",
     "start_time": "2022-08-23T19:38:02.266668Z"
    }
   },
   "outputs": [],
   "source": [
    "combined[combined>0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:02.540640Z",
     "start_time": "2022-08-23T19:38:02.528644Z"
    }
   },
   "outputs": [],
   "source": [
    "# for stability reasons add jitter\n",
    "combined += 0.0001*np.random.randn(combined.shape[0],combined.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:05.109077Z",
     "start_time": "2022-08-23T19:38:02.751665Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spa = SPA(resampled, combined,reps=10000)\n",
    "print(spa.compute())\n",
    "print(spa.pvalues)\n",
    "print(spa.better_models())\n",
    "print(spa.critical_values())\n",
    "spa.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:05.124087Z",
     "start_time": "2022-08-23T19:38:05.112045Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.random import rand\n",
    "from numpy import ix_\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:05.170261Z",
     "start_time": "2022-08-23T19:38:05.126048Z"
    }
   },
   "outputs": [],
   "source": [
    "def bootstrap_sample(data, B, w):\n",
    "    '''\n",
    "    Bootstrap the input data\n",
    "    data: input numpy data array\n",
    "    B: boostrap size\n",
    "    w: block length of the boostrap\n",
    "    '''\n",
    "    t = len(data)\n",
    "    p = 1 / w\n",
    "    indices = np.zeros((t, B), dtype=int)\n",
    "    indices[0, :] = np.ceil(t * rand(1, B))\n",
    "    select = np.asfortranarray(rand(B, t).T < p)\n",
    "    vals = np.ceil(rand(1, np.sum(np.sum(select))) * t).astype(int)\n",
    "    indices_flat = indices.ravel(order=\"F\")\n",
    "    indices_flat[select.ravel(order=\"F\")] = vals.ravel()\n",
    "    indices = indices_flat.reshape([B, t]).T\n",
    "    for i in range(1, t):\n",
    "        indices[i, ~select[i, :]] = indices[i - 1, ~select[i, :]] + 1\n",
    "    indices[indices > t] = indices[indices > t] - t\n",
    "    indices -= 1\n",
    "    return data[indices]\n",
    "\n",
    "\n",
    "def compute_dij(losses, bsdata):\n",
    "    '''Compute the loss difference'''\n",
    "    t, M0 = losses.shape\n",
    "    B = bsdata.shape[1]\n",
    "    dijbar = np.zeros((M0, M0))\n",
    "    for j in range(M0):\n",
    "        dijbar[j, :] = np.mean(losses - losses[:, [j]], axis=0)\n",
    "\n",
    "    dijbarstar = np.zeros((B, M0, M0))\n",
    "    for b in range(B):\n",
    "        meanworkdata = np.mean(losses[bsdata[:, b], :], axis=0)\n",
    "        for j in range(M0):\n",
    "            dijbarstar[b, j, :] = meanworkdata - meanworkdata[j]\n",
    "\n",
    "    vardijbar = np.mean((dijbarstar - np.expand_dims(dijbar, 0)) ** 2, axis=0)\n",
    "    vardijbar += np.eye(M0)\n",
    "\n",
    "    return dijbar, dijbarstar, vardijbar\n",
    "\n",
    "\n",
    "def calculate_PvalR(z, included, zdata0):\n",
    "    '''Calculate the p-value of relative algorithm'''\n",
    "    empdistTR = np.max(np.max(np.abs(z), 2), 1)\n",
    "    zdata = zdata0[ix_(included - 1, included - 1)]\n",
    "    TR = np.max(zdata)\n",
    "    pval = np.mean(empdistTR > TR)\n",
    "    return pval\n",
    "\n",
    "\n",
    "def calculate_PvalSQ(z, included, zdata0):\n",
    "    '''Calculate the p-value of sequential algorithm'''\n",
    "    empdistTSQ = np.sum(z ** 2, axis=1).sum(axis=1) / 2\n",
    "    zdata = zdata0[ix_(included - 1, included - 1)]\n",
    "    TSQ = np.sum(zdata ** 2) / 2\n",
    "    pval = np.mean(empdistTSQ > TSQ)\n",
    "    return pval\n",
    "\n",
    "\n",
    "def iterate(dijbar, dijbarstar, vardijbar, alpha, algorithm=\"R\"):\n",
    "    '''Iteratively excluding inferior model'''\n",
    "    B, M0, _ = dijbarstar.shape\n",
    "    z0 = (dijbarstar - np.expand_dims(dijbar, 0)) / np.sqrt(\n",
    "        np.expand_dims(vardijbar, 0)\n",
    "    )\n",
    "    zdata0 = dijbar / np.sqrt(vardijbar)\n",
    "\n",
    "    excludedR = np.zeros([M0, 1], dtype=int)\n",
    "    pvalsR = np.ones([M0, 1])\n",
    "\n",
    "    for i in range(M0 - 1):\n",
    "        included = np.setdiff1d(np.arange(1, M0 + 1), excludedR)\n",
    "        m = len(included)\n",
    "        z = z0[ix_(range(B), included - 1, included - 1)]\n",
    "\n",
    "        if algorithm == \"R\":\n",
    "            pvalsR[i] = calculate_PvalR(z, included, zdata0)\n",
    "        elif algorithm == \"SQ\":\n",
    "            pvalsR[i] = calculate_PvalSQ(z, included, zdata0)\n",
    "\n",
    "        scale = m / (m - 1)\n",
    "        dibar = np.mean(dijbar[ix_(included - 1, included - 1)], 0) * scale\n",
    "        dibstar = np.mean(dijbarstar[ix_(range(B), included - 1, included - 1)], 1) * (\n",
    "            m / (m - 1)\n",
    "        )\n",
    "        vardi = np.mean((dibstar - dibar) ** 2, axis=0)\n",
    "        t = dibar / np.sqrt(vardi)\n",
    "        modeltoremove = np.argmax(t)\n",
    "        excludedR[i] = included[modeltoremove]\n",
    "\n",
    "    maxpval = pvalsR[0]\n",
    "    for i in range(1, M0):\n",
    "        if pvalsR[i] < maxpval:\n",
    "            pvalsR[i] = maxpval\n",
    "        else:\n",
    "            maxpval = pvalsR[i]\n",
    "\n",
    "    excludedR[-1] = np.setdiff1d(np.arange(1, M0 + 1), excludedR)\n",
    "    pl = np.argmax(pvalsR > alpha)\n",
    "    includedR = excludedR[pl:]\n",
    "    excludedR = excludedR[:pl]\n",
    "    return includedR - 1, excludedR - 1, pvalsR\n",
    "\n",
    "\n",
    "def MCS2(losses, alpha, B, w, algorithm):\n",
    "    '''Main function of the MCS'''\n",
    "    t, M0 = losses.shape\n",
    "    bsdata = bootstrap_sample(np.arange(t), B, w)\n",
    "    dijbar, dijbarstar, vardijbar = compute_dij(losses, bsdata)\n",
    "    includedR, excludedR, pvalsR = iterate(\n",
    "        dijbar, dijbarstar, vardijbar, alpha, algorithm=algorithm\n",
    "    )\n",
    "    return includedR, excludedR, pvalsR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:05.201075Z",
     "start_time": "2022-08-23T19:38:05.173043Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelConfidenceSet(object):\n",
    "    def __init__(self, data, alpha, B, w, algorithm=\"SQ\", names=None):\n",
    "        \"\"\"\n",
    "        Implementation of Econometrica Paper:\n",
    "        Hansen, Peter R., Asger Lunde, and James M. Nason. \"The model confidence set.\" Econometrica 79.2 (2011): 453-497.\n",
    "\n",
    "        Input:\n",
    "            data->pandas.DataFrame or numpy.ndarray: input data, columns are the losses of each model \n",
    "            alpha->float: confidence level\n",
    "            B->int: bootstrap size for computation covariance\n",
    "            w->int: block size for bootstrap sampling\n",
    "            algorithm->str: SQ or R, SQ is the first t-statistics in Hansen (2011) p.465, and R is the second t-statistics\n",
    "            names->list: the name of each model (corresponding to each columns). \n",
    "\n",
    "        Method:\n",
    "            run(self): compute the MCS procedure\n",
    "\n",
    "        Attributes:\n",
    "            included: models that are in the model confidence sets at confidence level of alpha\n",
    "            excluded: models that are NOT in the model confidence sets at confidence level of alpha\n",
    "            pvalues: the bootstrap p-values of each models\n",
    "        \"\"\"\n",
    "\n",
    "        if isinstance(data, pd.DataFrame):\n",
    "            self.data = data.values\n",
    "            self.names = data.columns.values if names is None else names\n",
    "        elif isinstance(data, np.ndarray):\n",
    "            self.data = data\n",
    "            self.names = np.arange(data.shape[1]) if names is None else names\n",
    "\n",
    "        if alpha < 0 or alpha > 1:\n",
    "            raise ValueError(\n",
    "                f\"alpha must be larger than zero and less than 1, found {alpha}\"\n",
    "            )\n",
    "        if not isinstance(B, int):\n",
    "            try:\n",
    "                B = int(B)\n",
    "            except Exception as identifier:\n",
    "                raise RuntimeError(\n",
    "                    f\"Bootstrap size B must be a integer, fail to convert\", identifier\n",
    "                )\n",
    "        if B < 1:\n",
    "            raise ValueError(f\"Bootstrap size B must be larger than 1, found {B}\")\n",
    "        if not isinstance(w, int):\n",
    "            try:\n",
    "                w = int(w)\n",
    "            except Exception as identifier:\n",
    "                raise RuntimeError(\n",
    "                    f\"Bootstrap block size w must be a integer, fail to convert\",\n",
    "                    identifier,\n",
    "                )\n",
    "        if w < 1:\n",
    "            raise ValueError(f\"Bootstrap block size w must be larger than 1, found {w}\")\n",
    "\n",
    "        if algorithm not in [\"R\", \"SQ\"]:\n",
    "            raise TypeError(f\"Only R and SQ algorithm supported, found {algorithm}\")\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.B = B\n",
    "        self.w = w\n",
    "        self.algorithm = algorithm\n",
    "\n",
    "    def run(self):\n",
    "        included, excluded, pvals = MCS2(\n",
    "            self.data, self.alpha, self.B, self.w, self.algorithm\n",
    "        )\n",
    "\n",
    "        self.included = self.names[included].ravel().tolist()\n",
    "        self.excluded = self.names[excluded].ravel().tolist()\n",
    "        self.pvalues = pd.Series(pvals.ravel(), index=self.excluded + self.included)\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:05.233044Z",
     "start_time": "2022-08-23T19:38:05.205041Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(30)\n",
    "mcs = ModelConfidenceSet(combined, 0.5,3, 2000).run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-23T19:38:06.297844Z",
     "start_time": "2022-08-23T19:38:06.288858Z"
    }
   },
   "outputs": [],
   "source": [
    "mcs.included"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
